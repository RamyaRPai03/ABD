1. Load batting.csv into a mysql in a database battingdb and table batting
#create db:
create database battingdb;
#create table batting:
CREATE TABLE batting (
playerID varchar (20),
yearID int,
stint int,
teamID varchar (20),
lgID varchar (20),
G int,
G_batting int,
AB int,
R int,
H int,
2B int,
3B int,
HR int,
RBI int,
SB int,
CS int,
BB int,
SO int,
IBB int,
HBP int,
SH int,
SF int,
GIDP int,
G_old int
);
#load table from csv:
LOAD DATA INFILE '/home/cloudera/Desktop/Batting.csv' 
INTO TABLE batting 
FIELDS TERMINATED BY ',' 
ENCLOSED BY '"'
LINES TERMINATED BY '\n'
IGNORE 1 LINES;

******************************************************************************************

2. Sqoop the details into hdfs.
#sqoop into HDFS
sqoop import --connect jdbc:mysql://localhost/battingdb --username root --password cloudera --table batting --m 1 --target-dir /batting 

******************************************************************************************


3. Sqoop the details into hive.
#create db  in hive
create database sqoop_db;
#sqoop into hive
sqoop import --connect jdbc:mysql://localhost:3306/battingdb --username root --password cloudera --split-by yearID --table batting --target-dir /batting_hive_3 --fields-terminated-by "," --hive-import --create-hive-table --hive-table sqoop_db.batting

******************************************************************************************

4. Implement a PIG script to 
a) Find the total count of participation of G 112

Batting = LOAD '/home/cloudera/Desktop/Batting1.csv' USING PigStorage(',') as (playerID:chararray,yearID:int,
stint:int,teamID:chararray,lgID:chararray,G:int,G_batting:int,
AB:int,R:int,H:int,B2:int,B3:int,
HR:int,RBI:int,SB:int,CS:int,
BB:int,SO:int,IBB:int,HBP:int,
SH:int,SF:int,GIDP:int,G_old:int);
dump Batting;
g_filter = Filter Batting by G==112;
g_filter_all = GROUP g_filter all;
total_count = foreach g_filter_all generate COUNT(g_filter.G);
dump total_count;


b) Find the player details with "david" 
david  = Filter Batting by(playerID MATCHES 'david.*');
dump david;

c) Find the average count of "NL"
NL_filter = Filter Batting by lgID =='NL';
NL_Group = Group NL_filter All;
NL_avg = foreach NL_Group Generate AVG(NL_filter.G_batting);
DUMP NL_avg;

d) Find the count of teams
team_count = group Batting by teamID;
team_group = group team_count All;
result_count = foreach team_group generate COUNT(team_count);
dump result_count;


******************************************************************************************


5. Implement a Hive script to
a) Find the total count of player details with "david"
use sqoop_db;
select count(*) from batting where playerID like "david%";

b) Create a patition on the TEAMID
c) Create 3 buckets on the partition.

set hive.exec.dynamic.partition.mode=nonstrict;
set hive.exec.dynamic.partition=true;
set hive.enforce.bucketing=true;
set hive.exec.max.dynamic.partitions.pernode=2000;

create external table batting_part(playerID string,
yearID int,
stint int,
lgID string,
G int,
G_batting int,
AB int,
R int,
H int,
B2 int,
B3 int,
HR int,
RBI int,
SB int,
CS int,
BB int,
SO int,
IBB int,
HBP int,
SH int,
SF int,
GIDP int,
G_old int)
partitioned by (teamID string)
clustered by (lgID) INTO 3 buckets
row format delimited
fields terminated by ','
stored as textfile;

create table batting_hive(playerID string,
yearID int,
stint int,
teamID string,
lgID string,
G int,
G_batting int,
AB int,
R int,
H int,
B2 int,
B3 int,
HR int,
RBI int,
SB int,
CS int,
BB int,
SO int,
IBB int,
HBP int,
SH int,
SF int,
GIDP int,
G_old int)
row format delimited
fields terminated by ','
stored as textfile;

LOAD DATA LOCAL INPATH '/home/cloudera/Desktop/Batting.csv' OVERWRITE INTO TABLE batting_hive;

from batting_hive bat INSERT OVERWRITE TABLE batting_part PARTITION(teamID)
select bat.playerID,bat.yearID,
bat.stint ,bat.lgID ,
bat.G ,bat.G_batting ,
bat.AB ,bat.R ,bat.H ,
bat.B2 ,bat.B3 ,
bat.HR ,bat.RBI ,
bat.SB ,bat.CS ,bat.BB ,
bat.SO ,bat.IBB, bat.HBP,
bat.SH ,bat.SF,bat.GIDP,
bat.G_old,bat.teamID
DISTRIBUTE BY teamID;




d) Extract the details on player "aaronha01"
select * from batting_part where playerID='aaronha01';

e) Find the count of teams
select count(distinct(teamID)) from batting_hive;

******************************************************************************************


6. Using python, 
a) Write a map-reducer program to find the total count of the players

#get_ipython().run_line_magic('tb', '')
from mrjob.job import MRJob
from mrjob.step import MRStep
import sys  
class MRWordFrequencyCount(MRJob):
	def mapper1(self, _, lines):
		data = lines.split(',')
		players = data[0].strip()
		yield players,None	
	def combiner(self, word, counts):
		
		yield word,None			
		
		
	def reducer1(self, key, counts):

		yield "total players",key
	def reducer2(self, key,word):
		c =0
		# for i in word:
		# 		c+=1	
		
			
		yield key,len(list(word))
	def steps(self):
		return [ MRStep(mapper=self.mapper1,reducer=self.combiner),MRStep(reducer=self.reducer1),MRStep(reducer=self.reducer2)]

if __name__ == '__main__':
    MRWordFrequencyCount.run()


b) Write a map-reducer program to find the total number of the teams.
from mrjob.job import MRJob
from mrjob.step import MRStep
import sys  
class MRWordFrequencyCount(MRJob):
	def mapper1(self, _, lines):
		data = lines.split(',')
		players = data[3].strip()
		yield players,None	
	def combiner(self, word, counts):
		
		yield word,None			
		
		
	def reducer1(self, key, counts):

		yield "total teams",key
	def reducer2(self, key,word):
		c =0
		for i in word:
				c+=1	
		
			
		yield key,c
	def steps(self):
		return [ MRStep(mapper=self.mapper1,reducer=self.combiner),MRStep(reducer=self.reducer1),MRStep(reducer=self.reducer2)]



if __name__ == '__main__':
    MRWordFrequencyCount.run()


******************************************************************************************



7. Visualize

Visualize the battings.csv based on the frequency of player inclusion yearwise.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

dataset= pd.read_csv('E:/POOJA/ABD/DataFiles/Batting.csv')
df1=dataset.groupby('yearID')['playerID'].count()

df1.head(5)
plt.figure(figsize=(15,10),dpi=100)
plt.plot(df1,linestyle='dotted',marker='*',color='blue',label='Players')
plt.xlabel('Year')
plt.ylabel('Players included')
plt.show()



******************************************************************************************

8. From halloffame.csv


create table hof(hofID string,yearid int,votedBy string,ballots string,needed int,votes int,inducted int,category string,needed_note string)
row format delimited
fields terminated by ','
stored as textfile;

LOAD DATA LOCAL INPATH '/home/cloudera/Desktop/HallOfFame.csv' OVERWRITE INTO TABLE hof;

#List the managers.
select * from hof where category = 'Manager';

#Find the numbers of votes got year wise by "chancfr01h".
select yearid,sum(votes),hofid from hof where hofId="chancfr01h" group by yearid,hofid;
output:
1936	5	chancfr01h
1937	49	chancfr01h
1938	133	chancfr01h
1939	158	chancfr01h
1942	136	chancfr01h
1945	179	chancfr01h
1946	294	chancfr01h



#Count the votes got by each person overall.
select sum(votes),hofid from hof group by hofid;

******************************************************************************************

9. Using hive,partition by year.

create table hof_part(hofID string,votedBy string,ballots string,needed int,votes int,inducted int,category string,needed_note string)
partitioned by(yearid int)
row format delimited
fields terminated by ','
stored as textfile;

from hof hf INSERT OVERWRITE TABLE hof_part PARTITION(yearid)
select hf.hofID,hf.votedBy,hf.ballots,hf.needed,hf.votes,hf.inducted,hf.category,hf.needed_note,hf.yearid
DISTRIBUTE BY yearid;

#find the year wise count of participants,
select sum(votes),yearid from hof_part group by yearid;

#find the total votes got by the players.
select sum(votes),hofid from hof_part where category = 'Player' group by hofid;

******************************************************************************************

10. Using python, map-reducer, find the average votes on the year 1936.
#Total number of times each page is visited in the year 2014

from mrjob.job import MRJob



class MRmyjob(MRJob):
	def mapper(self,_,line):
		#split the line with tab separated fields
		data = line.split(',')
		date = data[1].strip()
		votes = data[5].strip()
		if date == '1936':
			yield "votes",votes
		

	

	def reducer(self, key, list_of_values):
		count = 0
		total = 0
		for x in list_of_values:
			total = total + float(x);
			count = count+1
			avglen = ("%.2f" % (total / count))
		yield key,avglen
	
if __name__ == '__main__':
	MRmyjob.run();

******************************************************************************************
